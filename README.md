# ğŸ¤– doc-chat â€“ Assistant IA local d'interrogation de docs de projet

**`doc-chat`** est un agent IA local qui vous permet dâ€™interroger la documentation de nâ€™importe quel projet Ã  partir de ses fichiers `.md`, `.adoc`, `.puml`, etc.

Il fonctionne **en local**, sans cloud, grÃ¢ce Ã  [Ollama](https://ollama.com) et [llama-index](https://github.com/jerryjliu/llama_index).

---

## ğŸ”§ PrÃ©requis

### 1. ğŸ Installer Python (via Scoop pour Windows)

```powershell
scoop install python
```

VÃ©rifiez lâ€™installation :

```bash
python --version
```

---

### 2. ğŸ¤– Installer Ollama

Suivre [https://ollama.com/download](https://ollama.com/download), puis tÃ©lÃ©charger le modÃ¨le par dÃ©faut (par exemple `mistral`) :

```bash
ollama run mistral
```

---

### 3. ğŸ“ PrÃ©parer votre projet source

Votre projet doit contenir :

- des fichiers `README.md`, `README.adoc`, etc. 
- Ã©ventuellement un dossier `doc/` Ã  la racine

---

## ğŸ”„ CrÃ©er et utiliser un environnement Python isolÃ© (`venv`)

### ğŸ§ª CrÃ©ation du venv

Dans un terminal Ã  la racine de `doc-chat` :

```bash
python -m venv .venv
```

### â–¶ï¸ Activation

**Sous PowerShell :**

```powershell
.venv\Scripts\Activate.ps1
```

**Sous CMD :**

```cmd
.venv\Scripts\activate.bat
```

**Sous Linux/macOS :**

```bash
source .venv/bin/activate
```

### ğŸ› ï¸ Installation des dÃ©pendances

Une fois le `venv` activÃ© :

```bash
pip install -r requirements.txt
```
Ensuite, copiez le fichier d'exemple pour crÃ©er votre configuration locale :
```bash
cp settings.example.json settings.json
```

---

## âš™ï¸ Configuration

1. Copiez le fichier d'exemple :

```bash
cp settings.example.json settings.json
```

2. Modifiez le fichier `settings.json` pour indiquer le **chemin local** du projet, les extensions Ã  indexer et les dossiers Ã  ignorer :
```json
{
  "project_root": "../chemin/vers/mon-projet/",
  "extensions": [".md", ".adoc"],
  "skip_dirs": [".venv"],
}
```

Ce fichier est ignorÃ© dans `.gitignore`.

---

## ğŸš€ Lancer lâ€™assistant

Une fois le venv activÃ© et les dÃ©pendances installÃ©es :

```bash
python app.py [--debug]
```
Lâ€™option `--debug` affiche les Ã©tapes dÃ©taillÃ©es et la liste des fichiers lus.

Une interface web sâ€™ouvrira automatiquement.

Si vous obtenez une erreur de type `RemoteProtocolError: Server disconnected`,
assurezâ€‘vous que le serveur **Ollama** est bien lancÃ© via `ollama serve` ou
`ollama run mistral` dans un autre terminal.

---

## ğŸ’¬ Exemples de questions

- "Quels modules contient ce projet ?"
- "Ã€ quoi sert le fichier `doc/architecture.puml` ?"
- "Comment lancer lâ€™application ?"

---

## ğŸ“ Structure du projet

```
doc-chat/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ settings.example.json
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ .venv/              â† non versionnÃ©, gÃ©nÃ©rÃ© localement
```

---

## ğŸ› ï¸ RÃ©installation rapide

```bash
git clone https://mon.gitlab/doc-chat.git
cd doc-chat
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
cp settings.example.json settings.json
# Modifier le fichier settings.json
ollama run mistral
python app.py
```

---

## âœ… Compatible avec Windows, Linux, macOS

Le projet est entiÃ¨rement local et fonctionne sur toutes les plateformes compatibles avec Python et Ollama.

---

## ğŸ“„ Licence

Ce projet est distribuÃ© sous la licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus d'informations.
